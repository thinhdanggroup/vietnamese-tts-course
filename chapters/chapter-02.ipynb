{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0b1c2d3",
   "metadata": {},
   "source": [
    "# Chapter 2 — Text Processing & Phonemization\n",
    "\n",
    "This notebook accompanies **Chapter 02** of the VieNeu-TTS deep learning guide.  \n",
    "We go from raw Vietnamese text all the way to the phoneme sequence that feeds the TTS model.\n",
    "\n",
    "**What we cover**:\n",
    "1. Unicode normalization — the silent killer of Vietnamese NLP pipelines\n",
    "2. Text normalization examples (numbers, dates, abbreviations)\n",
    "3. Vietnamese tones — visual and Unicode guide\n",
    "4. Running the VieNeu-TTS phonemization pipeline\n",
    "5. Tone contrast in phoneme output\n",
    "6. Tokenization — how text becomes token IDs"
   ]
  },
  {
   "id": "colab-setup-ch02",
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ── Colab auto-setup (safe to run locally too) ───────────────────\nimport sys, os\n\nif \"google.colab\" in sys.modules:\n    if not os.path.exists(\"/content/vietnamese-tts-course\"):\n        !git clone https://github.com/thinhdanggroup/vietnamese-tts-course.git /content/vietnamese-tts-course\n    os.chdir(\"/content/vietnamese-tts-course/chapters\")\n    !pip install -q librosa soundfile matplotlib\n\n    if not os.path.exists(\"/content/VieNeu-TTS\"):\n        !git clone https://github.com/pnnbao97/VieNeu-TTS.git /content/VieNeu-TTS\n        !pip install -q -e /content/VieNeu-TTS\n    sys.path.insert(0, \"/content/VieNeu-TTS\")\n    print(\"Colab setup complete.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c2d3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import unicodedata\n",
    "import json\n",
    "\n",
    "# Add VieNeu-TTS root to Python path so we can import vieneu_utils\n",
    "vieneu_root = os.path.abspath(\"..\")\n",
    "if vieneu_root not in sys.path:\n",
    "    sys.path.insert(0, vieneu_root)\n",
    "\n",
    "print(f\"Python: {sys.version.split()[0]}\")\n",
    "print(f\"VieNeu-TTS root added to path: {vieneu_root}\")\n",
    "print()\n",
    "\n",
    "# Verify the vieneu_utils package is accessible\n",
    "try:\n",
    "    import vieneu_utils\n",
    "    print(f\"vieneu_utils found at: {vieneu_utils.__file__}\")\n",
    "except ImportError as e:\n",
    "    print(f\"Warning: {e}\")\n",
    "    print(\"Some cells may not work. Make sure you are running from VieNeu-TTS/learning/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d3e4f5",
   "metadata": {},
   "source": [
    "## 1. Unicode Normalization — Vietnamese Diacritics\n",
    "\n",
    "Vietnamese uses many diacritics (tone marks + vowel modification marks). In Unicode, these can be encoded in two ways:\n",
    "\n",
    "- **NFC** (Canonical Composition): precomposed — `ế` is a **single** codepoint (U+1EBF)\n",
    "- **NFD** (Canonical Decomposition): decomposed — `ế` = `e` + `̂` + `́` = **three** codepoints\n",
    "\n",
    "**The critical bug**: `\"ế\"_NFC == \"ế\"_NFD` evaluates to `False` in Python, even though they look identical on screen. This breaks dictionary lookups, tokenizers, and G2P systems that don't normalize first.\n",
    "\n",
    "> Always call `unicodedata.normalize(\"NFC\", text)` at the start of your pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3e4f5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "# ============================================================\n",
    "# NFC vs NFD for Vietnamese\n",
    "# ============================================================\n",
    "\n",
    "# NFC: composed form — one codepoint per character\n",
    "text_nfc = \"Tiếng Việt\"  # Each accented letter is a single Unicode character\n",
    "text_nfd = unicodedata.normalize(\"NFD\", text_nfc)  # Decompose into base + combining marks\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"NFC (Composed) vs NFD (Decomposed) for Vietnamese\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Text (visual):   {text_nfc}\")\n",
    "print()\n",
    "print(f\"NFC repr: {text_nfc!r}\")\n",
    "print(f\"NFC len:  {len(text_nfc)} characters\")\n",
    "print(f\"NFC bytes (UTF-8): {text_nfc.encode('utf-8').hex()}\")\n",
    "print()\n",
    "print(f\"NFD repr: {text_nfd!r}\")\n",
    "print(f\"NFD len:  {len(text_nfd)} characters  ← MORE characters despite looking the same!\")\n",
    "print(f\"NFD bytes (UTF-8): {text_nfd.encode('utf-8').hex()}\")\n",
    "print()\n",
    "print(f\"NFC == NFD: {text_nfc == text_nfd}  ← This is the bug source\")\n",
    "print()\n",
    "\n",
    "# Show codepoints for each character\n",
    "print(\"Codepoint breakdown:\")\n",
    "print(f\"{'NFC codepoints':^40} | {'NFD codepoints':^50}\")\n",
    "print(\"-\" * 92)\n",
    "\n",
    "# Show first few characters\n",
    "for char_nfc in text_nfc:\n",
    "    name = unicodedata.name(char_nfc, 'UNKNOWN')\n",
    "    print(f\"  U+{ord(char_nfc):04X} {char_nfc!r:4s} {name}\")\n",
    "\n",
    "print()\n",
    "print(\"After NFD decomposition:\")\n",
    "for char_nfd in text_nfd:\n",
    "    name = unicodedata.name(char_nfd, 'UNKNOWN')\n",
    "    cat  = unicodedata.category(char_nfd)  # Mn = Mark, Non-spacing (combining marks)\n",
    "    print(f\"  U+{ord(char_nfd):04X} {char_nfd!r:4s} {cat:3s} {name}\")\n",
    "\n",
    "print()\n",
    "print(\"Fix: Always normalize to NFC\")\n",
    "text_fixed = unicodedata.normalize(\"NFC\", text_nfd)\n",
    "print(f\"After NFC normalization: len={len(text_fixed)}, matches original: {text_fixed == text_nfc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f5a6b7",
   "metadata": {},
   "source": [
    "## 2. Text Normalization Examples\n",
    "\n",
    "Before phonemization, raw Vietnamese text must be normalized: expand numbers, abbreviations, dates, currency, etc.  \n",
    "Below we show before/after normalization for common Vietnamese TTS input patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a6b7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Text Normalization Examples\n",
    "# ============================================================\n",
    "# Note: VieNeu-TTS has a normalize_text module. Here we show\n",
    "# the expected transformations to illustrate what normalization does.\n",
    "\n",
    "normalization_examples = [\n",
    "    {\n",
    "        \"category\": \"Cardinal Number\",\n",
    "        \"before\": \"Dân số Việt Nam đạt 100 triệu người.\",\n",
    "        \"after\":  \"Dân số Việt Nam đạt một trăm triệu người.\",\n",
    "        \"note\":   \"100 → 'một trăm'\"\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Year\",\n",
    "        \"before\": \"Năm 2024, AI bùng nổ mạnh mẽ.\",\n",
    "        \"after\":  \"Năm hai nghìn không trăm hai mươi tư, AI bùng nổ mạnh mẽ.\",\n",
    "        \"note\":   \"2024 → 'hai nghìn không trăm hai mươi tư'\"\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Currency\",\n",
    "        \"before\": \"Giá vé 250.000 đồng.\",\n",
    "        \"after\":  \"Giá vé hai trăm năm mươi nghìn đồng.\",\n",
    "        \"note\":   \"250.000 đồng (note: '.' is thousands separator in Vietnamese)\"\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Date\",\n",
    "        \"before\": \"Ngày 1/5/2024 là Quốc tế Lao động.\",\n",
    "        \"after\":  \"Ngày một tháng năm năm hai nghìn không trăm hai mươi tư là Quốc tế Lao động.\",\n",
    "        \"note\":   \"DD/MM/YYYY format\"\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Abbreviation\",\n",
    "        \"before\": \"TP.HCM là trung tâm kinh tế của VN.\",\n",
    "        \"after\":  \"Thành phố Hồ Chí Minh là trung tâm kinh tế của Việt Nam.\",\n",
    "        \"note\":   \"TP.HCM → 'Thành phố Hồ Chí Minh', VN → 'Việt Nam'\"\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Phone Number\",\n",
    "        \"before\": \"Gọi 0912 345 678 để được tư vấn.\",\n",
    "        \"after\":  \"Gọi không chín một hai ba bốn năm sáu bảy tám để được tư vấn.\",\n",
    "        \"note\":   \"Read digit by digit\"\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Mixed Code-Switching\",\n",
    "        \"before\": \"Mô hình AI sử dụng GPU NVIDIA để training.\",\n",
    "        \"after\":  \"Mô hình Ây ai sử dụng Giê-Pê-U En-vi-đi-a để trên-ning.\",\n",
    "        \"note\":   \"Foreign words use Vietnamese phonological adaptation\"\n",
    "    },\n",
    "    {\n",
    "        \"category\": \"Ordinal (Irregular)\",\n",
    "        \"before\": \"Đội xếp thứ 1 nhận huy chương vàng.\",\n",
    "        \"after\":  \"Đội xếp thứ nhất nhận huy chương vàng.\",\n",
    "        \"note\":   \"thứ 1 → 'thứ nhất' (irregular — NOT 'thứ một')\"\n",
    "    },\n",
    "]\n",
    "\n",
    "print(f\"{'Category':<20} | {'Before (raw)':^45} | {'After (normalized)':^50}\")\n",
    "print(\"-\" * 120)\n",
    "for ex in normalization_examples:\n",
    "    print(f\"{ex['category']:<20} | {ex['before']:45} | {ex['after']}\")\n",
    "    print(f\"{'':20} | Note: {ex['note']}\")\n",
    "    print(\"-\" * 120)\n",
    "\n",
    "print()\n",
    "print(\"Key insight: Number expansion rules in Vietnamese are context-sensitive.\")\n",
    "print(\"'5' → 'năm' (cardinal) or 'lăm' (after 20, 30, ...) or 'nhất' (1st ordinal).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b7c8d9",
   "metadata": {},
   "source": [
    "## 3. Vietnamese Tones — Visual Guide\n",
    "\n",
    "Vietnamese has **6 lexical tones** (thanh điệu). Each tone on the base vowel `a` creates a completely different word.  \n",
    "We show each tone's Unicode codepoint, F0 contour shape, phonation type, and an example word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c8d9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# The 6 tones on base vowel 'a'\n",
    "tones = {\n",
    "    \"ngang (flat)\":        {\"char\": \"a\",  \"number\": 1, \"f0\": [33, 33, 33, 33, 33], \"phonation\": \"Modal\",      \"example\": \"ma (ghost)\"},\n",
    "    \"huyền (falling)\":     {\"char\": \"à\",  \"number\": 2, \"f0\": [21, 18, 15, 13, 12], \"phonation\": \"Breathy\",    \"example\": \"mà (but)\"},\n",
    "    \"sắc (rising)\":        {\"char\": \"á\",  \"number\": 3, \"f0\": [35, 38, 41, 43, 45], \"phonation\": \"Modal\",      \"example\": \"má (cheek)\"},\n",
    "    \"hỏi (dipping)\":       {\"char\": \"ả\",  \"number\": 4, \"f0\": [32, 26, 22, 26, 32], \"phonation\": \"Modal\",      \"example\": \"mả (tomb)\"},\n",
    "    \"ngã (creaky rise)\":   {\"char\": \"ã\",  \"number\": 5, \"f0\": [33, 36, 30, 38, 44], \"phonation\": \"Creaky\",     \"example\": \"mã (horse)\"},\n",
    "    \"nặng (low falling)\":  {\"char\": \"ạ\",  \"number\": 6, \"f0\": [21, 17, 14, 11, 10], \"phonation\": \"Constricted\",\"example\": \"mạ (rice seedling)\"},\n",
    "}\n",
    "\n",
    "print(\"Vietnamese 6-Tone System — Unicode and Phonological Properties\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Tone Name':<22} {'Char':^6} {'Unicode':^12} {'UTF-8 bytes':^24} {'NFC len':^8} {'Phonation':<14} {'Example'}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "for name, info in tones.items():\n",
    "    char = info[\"char\"]\n",
    "    codepoint = f\"U+{ord(char):04X}\"\n",
    "    utf8_hex  = char.encode('utf-8').hex()\n",
    "    nfc_len   = len(unicodedata.normalize('NFC', char))\n",
    "    print(f\"{name:<22} {char:^6} {codepoint:^12} {utf8_hex:^24} {nfc_len:^8} {info['phonation']:<14} {info['example']}\")\n",
    "\n",
    "print()\n",
    "print(\"F0 contour notation (Chao, 1930): 1=lowest pitch, 5=highest pitch\")\n",
    "print(\"The same base 'a' vowel, 6 completely different words!\")\n",
    "\n",
    "# Visualize F0 contours\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "colors_map = {\n",
    "    \"ngang (flat)\":       '#2196F3',\n",
    "    \"huyền (falling)\":    '#9C27B0',\n",
    "    \"sắc (rising)\":       '#4CAF50',\n",
    "    \"hỏi (dipping)\":      '#FF9800',\n",
    "    \"ngã (creaky rise)\":  '#F44336',\n",
    "    \"nặng (low falling)\": '#795548',\n",
    "}\n",
    "linestyles = ['-', '--', '-', '--', '-.', ':']\n",
    "\n",
    "t = np.linspace(0, 1, 5)\n",
    "\n",
    "for (name, info), ls in zip(tones.items(), linestyles):\n",
    "    f0_normalized = np.array(info[\"f0\"])  # Chao tone letters (1-5 scale)\n",
    "    ax.plot(t, f0_normalized, color=colors_map[name], linestyle=ls, linewidth=2.5,\n",
    "            marker='o', markersize=5,\n",
    "            label=f\"{info['char']} — {name}\")\n",
    "\n",
    "    # Label the endpoint\n",
    "    ax.annotate(info['char'], xy=(t[-1], f0_normalized[-1]),\n",
    "                xytext=(t[-1]+0.02, f0_normalized[-1]),\n",
    "                fontsize=14, color=colors_map[name], fontweight='bold')\n",
    "\n",
    "ax.set_yticks([1, 2, 3, 4, 5])\n",
    "ax.set_yticklabels(['1 (Low)', '2', '3 (Mid)', '4', '5 (High)'])\n",
    "ax.set_xticks([0, 0.25, 0.5, 0.75, 1.0])\n",
    "ax.set_xticklabels(['Start', '25%', '50%', '75%', 'End'])\n",
    "ax.set_xlabel(\"Normalized syllable time position\", fontsize=12)\n",
    "ax.set_ylabel(\"Pitch height (Chao tone scale)\", fontsize=12)\n",
    "ax.set_title(\"F0 Contours of Vietnamese 6 Tones\\n(Schematic based on Northern Vietnamese)\",\n",
    "             fontsize=13, fontweight='bold')\n",
    "ax.legend(loc='lower right', fontsize=9, framealpha=0.9)\n",
    "ax.set_ylim(0.5, 5.5)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add phonation type annotations\n",
    "ax.text(0.02, 4.5, 'Creaky phonation →\\n(ngã)', fontsize=8, color='#F44336', alpha=0.7)\n",
    "ax.text(0.02, 1.5, '← Breathy phonation\\n    (huyền)', fontsize=8, color='#9C27B0', alpha=0.7)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ch02_tones.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKey insight: Two tones with similar F0 (huyền vs nặng) are distinguished by PHONATION TYPE.\")\n",
    "print(\"  huyền: breathy + gradual falling\")\n",
    "print(\"  nặng:  constricted + short, abrupt end\")\n",
    "print(\"This is why F0 alone is insufficient — TTS must also model phonation type.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d9e0f1",
   "metadata": {},
   "source": [
    "## 4. Running the Phonemization Pipeline\n",
    "\n",
    "VieNeu-TTS uses a **hybrid** phonemization strategy:\n",
    "1. **Dictionary lookup** (primary) — high accuracy for common Vietnamese words\n",
    "2. **eSpeak-NG fallback** — handles OOV words, foreign words, rare forms\n",
    "\n",
    "The function `phonemize_with_dict(text)` implements this pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e0f1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "try:\n",
    "    from vieneu_utils.phonemize_text import phonemize_with_dict\n",
    "    print(\"phonemize_with_dict imported successfully\")\n",
    "    PHONEMIZER_AVAILABLE = True\n",
    "except ImportError as e:\n",
    "    print(f\"Import failed: {e}\")\n",
    "    print(\"Showing expected output instead.\")\n",
    "    PHONEMIZER_AVAILABLE = False\n",
    "\n",
    "test_sentences = [\n",
    "    \"Xin chào, tôi là VieNeu.\",\n",
    "    \"Hệ thống TTS hoạt động tốt.\",\n",
    "    \"Năm 2024, AI phát triển mạnh mẽ.\",\n",
    "    \"Machine learning rất thú vị.\",       # code-switching\n",
    "    \"Hà Nội là thủ đô của Việt Nam.\",\n",
    "    \"ma, mà, má, mả, mã, mạ\",             # all 6 tones on 'a'\n",
    "]\n",
    "\n",
    "# Expected outputs (for when phonemizer is not installed)\n",
    "expected_outputs = [\n",
    "    \"s i n tɕ aː w˨˩˦ t o j˧ l aː v i e n ø˧\",\n",
    "    \"h e˨˩ tʰ oŋ˧˩ t e j e s˧ h w a t˧ ɗ oŋ˧ t o t˧˥\",\n",
    "    \"n a m˧ h a j ŋ i n˧ k ʰ oŋ˧ tɕ a m˧ h a j m ɯ ə j t ɯ˧ a j˧ f a t˧˥ tɕ j en˧ m a ɲ˧ m e˨˩\",\n",
    "    \"m ə ɕ i n l ɜː n ɪ ŋ r a t˧˥ tʰ u˧˩ v i˨˩\",\n",
    "    \"h aː˧ n oj˧ l aː˧ tʰ u˧˩ ɗ oː˧ k ɯ a˧ v iɛ t˨˩ n a m˧\",\n",
    "    \"m a˧ m aː˨˩ m a˧˥ m a˧˩˧ m aː˨˩˦ m a˨˩\",\n",
    "]\n",
    "\n",
    "print(\"\\nPhoneme output:\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "for i, (sent, expected) in enumerate(zip(test_sentences, expected_outputs)):\n",
    "    print(f\"\\nExample {i+1}:\")\n",
    "    print(f\"  Input:    {sent}\")\n",
    "    if PHONEMIZER_AVAILABLE:\n",
    "        try:\n",
    "            phonemes = phonemize_with_dict(sent)\n",
    "            print(f\"  Phonemes: {phonemes}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error: {e}\")\n",
    "            print(f\"  Expected: {expected}\")\n",
    "    else:\n",
    "        print(f\"  Phonemes: {expected}  [expected output]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f1a2b3",
   "metadata": {},
   "source": [
    "## 5. Tone Contrast in Phoneme Output\n",
    "\n",
    "The 6 Vietnamese tones appear as **different phoneme symbols** in the output. Specifically, tone marks are encoded as suprasegmental markers in the phoneme string. Here we compare the same base syllable with all 6 tones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a2b3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tone contrast: same base syllable 'ba' with all 6 tones\n",
    "# 'ba' = father (ngang), 'bà' = grandmother (huyền), 'bá' = magistrate (sắc)\n",
    "# 'bả' = bait/drug (hỏi), 'bã' = dregs (ngã), 'bạ' = random/haphazard (nặng)\n",
    "\n",
    "tone_minimal_pairs = [\n",
    "    (\"ba\",  \"Ngang  (flat, high-mid)\",    \"ba (three)\"),\n",
    "    (\"bà\",  \"Huyền  (falling, low)\",      \"bà (grandmother)\"),\n",
    "    (\"bá\",  \"Sắc    (rising, high)\",      \"bá (magistrate)\"),\n",
    "    (\"bả\",  \"Hỏi   (dipping, mid)\",      \"bả (bait/poison)\"),\n",
    "    (\"bã\",  \"Ngã   (creaky rise)\",        \"bã (dregs, sediment)\"),\n",
    "    (\"bạ\",  \"Nặng  (low falling, short)\", \"bạ (haphazard)\"),\n",
    "]\n",
    "\n",
    "print(\"Tone Minimal Pairs — same consonant /b/ + vowel /a/, 6 different words\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"{'Word':<6} {'Tone Name':<25} {'Meaning':<25} {'Phoneme (IPA approx)'}\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# IPA representations for 'ba' in each tone (Northern Vietnamese)\n",
    "ipa_map = {\n",
    "    \"ba\": \"/ba˧/    — mid level\",\n",
    "    \"bà\": \"/ba˨˩/   — low falling, breathy\",\n",
    "    \"bá\": \"/ba˧˥/   — mid-high rising\",\n",
    "    \"bả\": \"/ba˧˩˧/  — mid dipping then rising\",\n",
    "    \"bã\": \"/ba˧˨˩˥/ — glottalized, creaky rise\",\n",
    "    \"bạ\": \"/ba˨˩/   — low falling, short, constricted\",\n",
    "}\n",
    "\n",
    "for word, tone_name, meaning in tone_minimal_pairs:\n",
    "    ipa = ipa_map.get(word, \"?\")\n",
    "    print(f\"{word:<6} {tone_name:<25} {meaning:<25} {ipa}\")\n",
    "\n",
    "print()\n",
    "print(\"Phonological note:\")\n",
    "print(\"  huyền vs nặng: Both fall, but huyền is breathy and longer; nặng is constricted and shorter.\")\n",
    "print(\"  ngã: The creaky break (glottal constriction) happens around the middle of the vowel.\")\n",
    "\n",
    "# Show phonemization if available\n",
    "if PHONEMIZER_AVAILABLE:\n",
    "    print()\n",
    "    print(\"VieNeu-TTS phoneme output:\")\n",
    "    print(\"-\" * 50)\n",
    "    for word, tone_name, meaning in tone_minimal_pairs:\n",
    "        try:\n",
    "            ph = phonemize_with_dict(word)\n",
    "            print(f\"  {word} → {ph}  ({tone_name})\")\n",
    "        except Exception as e:\n",
    "            print(f\"  {word} → [error: {e}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b3c4d5",
   "metadata": {},
   "source": [
    "## 6. Tokenization\n",
    "\n",
    "In VieNeu-TTS, text is not fed as raw characters but as **token IDs** from a learned vocabulary. The tokenizer maps Vietnamese words/subwords to integer IDs that the LLM can process.\n",
    "\n",
    "Key concepts:\n",
    "- **BPE (Byte-Pair Encoding)**: Common subword tokenization algorithm. Starts from characters, merges frequent pairs.\n",
    "- **Vietnamese syllable = 1 token** (usually): Because Vietnamese is monosyllabic and BPE vocabulary includes common syllables.\n",
    "- **Special tokens**: `TEXT_START`, `TEXT_END`, `SPEECH_START`, `SPEECH_END`, `SPEECH_GEN_START`, `SPEECH_GEN_END` structure the LLM prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c4d5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Tokenization Analysis\n",
    "# ============================================================\n",
    "# We demonstrate tokenization concepts even without the full VieNeu-TTS tokenizer\n",
    "\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Attempt to load VieNeu-TTS tokenizer\n",
    "TOKENIZER_AVAILABLE = False\n",
    "try:\n",
    "    # Try to find the model configuration\n",
    "    config_path = \"../config.yaml\"\n",
    "    if os.path.exists(config_path):\n",
    "        print(f\"Found config: {config_path}\")\n",
    "    \n",
    "    # Try to import tokenizer components\n",
    "    from vieneu_utils.core_utils import load_tokenizer\n",
    "    TOKENIZER_AVAILABLE = True\n",
    "    print(\"Tokenizer loaded successfully\")\n",
    "except (ImportError, AttributeError) as e:\n",
    "    print(f\"Tokenizer not available: {e}\")\n",
    "    print(\"Showing conceptual demonstration instead.\")\n",
    "\n",
    "print()\n",
    "\n",
    "# ============================================================\n",
    "# Conceptual tokenization demonstration\n",
    "# ============================================================\n",
    "\n",
    "# Vietnamese sentences and approximate token counts\n",
    "# (BPE tokenizer trained on Vietnamese usually gives 1-2 tokens per syllable)\n",
    "sentences = [\n",
    "    \"Xin chào.\",\n",
    "    \"Hệ thống TTS hoạt động tốt.\",\n",
    "    \"Năm 2024, AI phát triển mạnh mẽ.\",\n",
    "    \"Machine learning rất thú vị.\",\n",
    "    \"Hà Nội là thủ đô của Việt Nam.\",\n",
    "]\n",
    "\n",
    "# Approximate character and word (syllable) counts\n",
    "print(\"Vietnamese Tokenization Statistics\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Sentence':<45} {'Chars':>6} {'Words':>6} {'Est. Tokens':>12} {'Est. Speech Tok':>16}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for sent in sentences:\n",
    "    n_chars = len(sent)\n",
    "    n_words = len(sent.split())  # Vietnamese word = syllable\n",
    "    # BPE estimate: Vietnamese syllables often 1 token, English words 1-2 tokens\n",
    "    n_tokens_est = n_words + 2  # +2 for common punctuation/subword splits\n",
    "    # Speech tokens: NeuCodec at 75 tok/s, typical 0.3-0.5s per syllable\n",
    "    speech_duration_est = n_words * 0.35  # 350ms per syllable (average)\n",
    "    n_speech_tokens_est = int(speech_duration_est * 75)  # 75 tokens/second\n",
    "    print(f\"{sent[:44]:<45} {n_chars:>6} {n_words:>6} {n_tokens_est:>12} {n_speech_tokens_est:>16}\")\n",
    "\n",
    "print()\n",
    "print(\"Key ratio: Speech tokens ≈ 40-80× text tokens\")\n",
    "print(\"Example: 10 text tokens → ~600-900 speech tokens for a 10-word sentence\")\n",
    "print()\n",
    "print(\"This is why LLM context length is critical for long-form TTS synthesis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d5e6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Special Tokens and Prompt Format\n",
    "# ============================================================\n",
    "\n",
    "print(\"VieNeu-TTS LLM Prompt Format\")\n",
    "print(\"=\" * 70)\n",
    "print()\n",
    "print(\"Special tokens that structure the input-output format:\")\n",
    "print()\n",
    "\n",
    "special_tokens = [\n",
    "    (\"<|text_start|>\",      \"TEXT_PROMPT_START\",       \"Begins the phonemized text section\"),\n",
    "    (\"<|text_end|>\",        \"TEXT_PROMPT_END\",         \"Ends the phonemized text section\"),\n",
    "    (\"<|speech_start|>\",    \"SPEECH_PROMPT_START\",     \"Begins reference speaker audio tokens\"),\n",
    "    (\"<|speech_end|>\",      \"SPEECH_PROMPT_END\",       \"Ends reference speaker audio tokens\"),\n",
    "    (\"<|speech_gen_start|>\",\"SPEECH_GENERATION_START\", \"Model begins generating speech tokens here\"),\n",
    "    (\"<|speech_gen_end|>\",  \"SPEECH_GENERATION_END\",   \"End-of-generation signal\"),\n",
    "]\n",
    "\n",
    "for token, name, description in special_tokens:\n",
    "    print(f\"  {token:<25} ({name:<25}) — {description}\")\n",
    "\n",
    "print()\n",
    "print(\"Full prompt for zero-shot voice cloning:\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "text_input = \"Xin chào Việt Nam\"\n",
    "# Simulated phoneme tokens (in real system, these come from phonemize_with_dict)\n",
    "phoneme_tokens = [\"s\", \"in\", \"tɕ\", \"aː\", \"w\", \"v\", \"iɛt\", \"n\", \"a\", \"m\"]\n",
    "# Simulated reference speech tokens (first codebook of NeuCodec)\n",
    "ref_speech_tokens = [\"<|speech_234|>\", \"<|speech_891|>\", \"<|speech_45|>\",\n",
    "                     \"<|speech_567|>\", \"<|speech_123|>\", \"...\"]\n",
    "# Simulated generated tokens\n",
    "gen_speech_tokens = [\"<|speech_412|>\", \"<|speech_789|>\", \"<|speech_56|>\",\n",
    "                     \"<|speech_890|>\", \"<|speech_234|>\", \"...\"]\n",
    "\n",
    "prompt = f\"\"\"\n",
    "<|text_start|>\n",
    "  {' '.join(phoneme_tokens)}\n",
    "<|text_end|>\n",
    "<|speech_start|>\n",
    "  {' '.join(ref_speech_tokens)}\n",
    "<|speech_end|>\n",
    "<|speech_gen_start|>\n",
    "  ← LLM autoregressively generates:\n",
    "  {' '.join(gen_speech_tokens)}\n",
    "<|speech_gen_end|>\n",
    "\"\"\"\n",
    "\n",
    "print(prompt)\n",
    "print(\"The LLM sees ONLY token IDs — text tokens and speech tokens live in the same vocabulary.\")\n",
    "print(\"Zero-shot cloning = providing reference speaker tokens as context (in-context learning).\")\n",
    "print(\"No fine-tuning needed — the model clones the voice through the context.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e6f7a8",
   "metadata": {},
   "source": [
    "## Analysis — Token Budget for Vietnamese TTS\n",
    "\n",
    "Understanding the token budget is critical for designing production VieNeu-TTS systems.\n",
    "\n",
    "**Given**: NeuCodec runs at ~75 speech tokens/second at 24 kHz.  \n",
    "**Context limit**: 4096 tokens (typical LLM)\n",
    "\n",
    "| Component | Tokens | Notes |\n",
    "|-----------|--------|-------|\n",
    "| Special tokens | ~6 | Fixed overhead |\n",
    "| Text (phonemes) | ~20-50 | 10-25 Vietnamese words |\n",
    "| Reference speech | ~300-600 | 4-8 seconds of reference audio |\n",
    "| Generated speech | **3000-3700** | **Remaining budget** |\n",
    "| **Generated duration** | **~40-50 seconds** | At 75 tok/s |\n",
    "\n",
    "**Conclusion**: With a 4096-token context, VieNeu-TTS can generate approximately 40-50 seconds of speech per inference call — sufficient for most TTS use cases. For longer texts, chunking at sentence or paragraph boundaries is required.\n",
    "\n",
    "Next: **Chapter 03** covers the full TTS architecture evolution — from concatenative to LLM-based, with full mathematical derivations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}