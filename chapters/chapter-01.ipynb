{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": [
    "# Chapter 1 — Audio Fundamentals: Hands-On with Vietnamese Speech\n",
    "\n",
    "This notebook accompanies **Chapter 01** of the VieNeu-TTS deep learning guide.  \n",
    "We will go from a raw Vietnamese WAV file all the way to MFCCs, building every representation by hand so you can see exactly what each step does.\n",
    "\n",
    "**Prerequisites**: Python 3.9+, librosa, numpy, matplotlib, soundfile\n",
    "\n",
    "**What we cover**:\n",
    "1. Load a Vietnamese audio sample\n",
    "2. Visualize the waveform (time domain)\n",
    "3. Compute and visualize the STFT\n",
    "4. Build the Mel spectrogram\n",
    "5. Extract MFCCs + delta features\n",
    "6. Demonstrate Nyquist aliasing\n",
    "7. Explore the time-frequency resolution trade-off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2c3d4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "librosa version: 0.11.0\n",
      "numpy version:   2.0.2\n",
      "All imports successful.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "examples/audio_ref/ not found. Clone the repo: git clone https://github.com/thinhdanggroup/vietnamese-tts-course.git",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipython-input-303941165.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m     )\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mEXAMPLES_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_find_examples_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Examples dir: {EXAMPLES_DIR}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipython-input-303941165.py\u001b[0m in \u001b[0;36m_find_examples_dir\u001b[0;34m()\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_candidate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_candidate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     raise FileNotFoundError(\n\u001b[0m\u001b[1;32m     38\u001b[0m         \u001b[0;34m\"examples/audio_ref/ not found. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;34m\"Clone the repo: git clone https://github.com/thinhdanggroup/vietnamese-tts-course.git\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: examples/audio_ref/ not found. Clone the repo: git clone https://github.com/thinhdanggroup/vietnamese-tts-course.git"
     ]
    }
   ],
   "source": [
    "# Install dependencies if needed\n",
    "# Uncomment the line below if running in a fresh environment\n",
    "# !pip install librosa numpy matplotlib soundfile ipython\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "# Set matplotlib style for clear plots\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['font.size'] = 11\n",
    "\n",
    "print(f\"librosa version: {librosa.__version__}\")\n",
    "print(f\"numpy version:   {np.__version__}\")\n",
    "print(\"All imports successful.\")\n",
    "\n",
    "# ── Path resolver (works regardless of Jupyter CWD) ──────────────\n",
    "from pathlib import Path\n",
    "import os as _os\n",
    "\n",
    "def _find_examples_dir():\n",
    "    # Walk up from CWD (works locally when kernel starts in chapters/)\n",
    "    for _p in [Path(_os.getcwd())] + list(Path(_os.getcwd()).parents):\n",
    "        _d = _p / \"examples\" / \"audio_ref\"\n",
    "        if _d.is_dir():\n",
    "            return _d\n",
    "    # Colab fallback paths\n",
    "    for _candidate in [\n",
    "        Path(\"/content/vietnamese-tts-course/examples/audio_ref\"),\n",
    "        Path(\"/content/VieNeu-TTS/examples/audio_ref\"),\n",
    "    ]:\n",
    "        if _candidate.is_dir():\n",
    "            return _candidate\n",
    "    raise FileNotFoundError(\n",
    "        \"examples/audio_ref/ not found. \"\n",
    "        \"Clone the repo: git clone https://github.com/thinhdanggroup/vietnamese-tts-course.git\"\n",
    "    )\n",
    "\n",
    "EXAMPLES_DIR = _find_examples_dir()\n",
    "print(f\"Examples dir: {EXAMPLES_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d4e5f6",
   "metadata": {},
   "source": [
    "## 1. Load a Vietnamese Audio Sample\n",
    "\n",
    "We load the VieNeu-TTS reference audio sample — a short Vietnamese sentence spoken by a native speaker.  \n",
    "The key parameters we need to know:\n",
    "- **Sample rate** `sr`: How many samples per second (should be 24,000 Hz for VieNeu-TTS)\n",
    "- **Duration**: Length of the audio in seconds\n",
    "- **Samples**: Total number of discrete amplitude values in the array\n",
    "\n",
    "> **Mathematical reminder**: The digital audio array `y` satisfies `y[n] = x(n / sr)` where `x(t)` is the original analog pressure wave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4e5f6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "from IPython.display import Audio\n",
    "\n",
    "# Load example audio (VieNeu-TTS reference sample)\n",
    "# sr=None preserves the original sample rate instead of resampling to 22050 Hz\n",
    "audio_path = str(EXAMPLES_DIR / \"example.wav\")\n",
    "y, sr = librosa.load(audio_path, sr=None)\n",
    "\n",
    "print(f\"Sample rate:      {sr} Hz\")\n",
    "print(f\"Duration:         {len(y)/sr:.3f} s\")\n",
    "print(f\"Total samples:    {len(y):,}\")\n",
    "print(f\"Data type:        {y.dtype}\")\n",
    "print(f\"Amplitude range:  [{y.min():.4f}, {y.max():.4f}]\")\n",
    "print(f\"Nyquist limit:    {sr//2:,} Hz  (max representable frequency)\")\n",
    "print()\n",
    "print(f\"This audio covers frequencies up to {sr//2} Hz.\")\n",
    "print(f\"Vietnamese speech critical range: 80 Hz (F0) to ~12000 Hz (fricatives).\")\n",
    "print(f\"Both are well within the {sr//2} Hz Nyquist limit.\")\n",
    "\n",
    "# Play audio in notebook\n",
    "Audio(y, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f6a7b8",
   "metadata": {},
   "source": [
    "## 2. Waveform — Time Domain\n",
    "\n",
    "The **waveform** is the most basic representation: a 1D array of amplitude values over time.  \n",
    "Each sample `y[n]` is the air pressure displacement at time `t = n / sr` seconds.\n",
    "\n",
    "For Vietnamese speech, different tones have visually distinct waveform shapes:\n",
    "- **Ngang** (flat tone): Regular, uniform cycles with stable amplitude\n",
    "- **Huyền** (falling tone): Cycles gradually lengthen (period increases = pitch falls); slightly irregular amplitude (breathiness)\n",
    "- **Sắc** (rising tone): Cycles get shorter (period decreases = pitch rises); amplitude increases\n",
    "- **Nặng** (low falling): Short duration, abrupt termination\n",
    "\n",
    "$$x(t) = A\\cos(2\\pi f_0(t) \\cdot t + \\phi)$$\n",
    "\n",
    "where $f_0(t)$ varies over time according to the tone contour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a7b8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(2, 1, figsize=(14, 6))\n",
    "\n",
    "# --- Full waveform ---\n",
    "ax = axes[0]\n",
    "librosa.display.waveshow(y, sr=sr, ax=ax, color='steelblue', alpha=0.8)\n",
    "ax.set_title(\"Vietnamese Speech Waveform (full utterance)\", fontsize=13, fontweight='bold')\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.set_ylabel(\"Amplitude\")\n",
    "ax.axhline(0, color='gray', linewidth=0.5)\n",
    "\n",
    "# Annotate approximate tone regions (adjust times based on your audio)\n",
    "tone_annotations = [\n",
    "    (0.0, 0.4, 'Ngang\\n(flat)'),\n",
    "    (0.5, 0.9, 'Sắc\\n(rising)'),\n",
    "    (1.0, 1.5, 'Huyền\\n(falling)'),\n",
    "]\n",
    "colors_tone = ['#2196F3', '#4CAF50', '#FF9800']\n",
    "for (t_start, t_end, label), color in zip(tone_annotations, colors_tone):\n",
    "    ax.axvspan(t_start, t_end, alpha=0.12, color=color)\n",
    "    ax.text((t_start + t_end)/2, ax.get_ylim()[1]*0.85, label,\n",
    "            ha='center', fontsize=8, color=color, fontweight='bold')\n",
    "\n",
    "# --- Zoomed waveform to see individual cycles ---\n",
    "ax2 = axes[1]\n",
    "zoom_start_s = 0.1\n",
    "zoom_dur_s   = 0.04  # 40 ms — shows ~4–6 cycles at 150 Hz F0\n",
    "zoom_start = int(zoom_start_s * sr)\n",
    "zoom_end   = int((zoom_start_s + zoom_dur_s) * sr)\n",
    "t_zoom = np.arange(zoom_start, zoom_end) / sr\n",
    "ax2.plot(t_zoom, y[zoom_start:zoom_end], color='crimson', linewidth=1.5)\n",
    "ax2.set_title(f\"Zoomed view [{zoom_start_s:.2f}–{zoom_start_s+zoom_dur_s:.2f}s] — individual oscillation cycles visible\",\n",
    "              fontsize=11)\n",
    "ax2.set_xlabel(\"Time (s)\")\n",
    "ax2.set_ylabel(\"Amplitude\")\n",
    "ax2.axhline(0, color='gray', linewidth=0.5)\n",
    "\n",
    "# Annotate one period\n",
    "ax2.annotate('', xy=(t_zoom[15], -0.3), xytext=(t_zoom[0], -0.3),\n",
    "             arrowprops=dict(arrowstyle='<->', color='purple', lw=1.5))\n",
    "ax2.text((t_zoom[0]+t_zoom[15])/2, -0.38, 'T = 1/F₀', ha='center', fontsize=9, color='purple')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ch01_waveform.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nIf F0 ≈ 150 Hz (typical Vietnamese male), one period T = {1/150*1000:.2f} ms\")\n",
    "print(f\"At sr={sr} Hz, one period = {sr/150:.0f} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b8c9d0",
   "metadata": {},
   "source": [
    "## 3. Short-Time Fourier Transform (STFT)\n",
    "\n",
    "The **STFT** gives us a 2D time-frequency representation by computing the DFT on short overlapping windows:\n",
    "\n",
    "$$X[m, k] = \\sum_{n} x[n] \\, w[n - mH] \\, e^{-j2\\pi kn/N}$$\n",
    "\n",
    "where $m$ = frame index, $k$ = frequency bin, $H$ = hop length, $N$ = FFT size.\n",
    "\n",
    "**Key parameters and their effect**:\n",
    "- `n_fft` ($N$): FFT size → frequency resolution $\\Delta f = f_s / N$ Hz per bin\n",
    "- `hop_length` ($H$): Step between frames → time resolution $\\Delta t = H / f_s$ seconds\n",
    "- `win_length`: Window size (default = n_fft)\n",
    "\n",
    "The output `D` is a complex matrix with shape `(1 + n_fft//2, n_frames)`.  \n",
    "The **magnitude** `|D|` tells us how much of each frequency is present; the **phase** `angle(D)` tells us the phase offset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c9d0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute STFT with VieNeu-TTS default parameters\n",
    "n_fft      = 1024\n",
    "hop_length = 256\n",
    "win_length = 1024\n",
    "\n",
    "D = librosa.stft(y, n_fft=n_fft, hop_length=hop_length, win_length=win_length,\n",
    "                 window='hann', center=True)\n",
    "\n",
    "magnitude = np.abs(D)       # |X[m,k]|  — always non-negative\n",
    "phase     = np.angle(D)     # angle(X[m,k]) — in [-pi, pi]\n",
    "power     = magnitude ** 2  # |X[m,k]|^2\n",
    "\n",
    "print(\"=== STFT Properties ===\")\n",
    "print(f\"n_fft:               {n_fft} samples\")\n",
    "print(f\"hop_length:          {hop_length} samples\")\n",
    "print(f\"STFT shape:          {D.shape}  (freq_bins × time_frames)\")\n",
    "print(f\"Freq bins:           {D.shape[0]}  (0 to {sr//2} Hz)\")\n",
    "print(f\"Time frames:         {D.shape[1]}\")\n",
    "print()\n",
    "print(f\"Frequency resolution: Δf = {sr}/{n_fft} = {sr/n_fft:.2f} Hz per bin\")\n",
    "print(f\"Time resolution:      Δt = {hop_length}/{sr} = {hop_length/sr*1000:.2f} ms per frame\")\n",
    "print(f\"Window duration:      {win_length}/{sr}*1000 = {win_length/sr*1000:.2f} ms\")\n",
    "print()\n",
    "print(f\"For Vietnamese F0 = 150 Hz:\")\n",
    "print(f\"  F0 falls in bin #{150 // (sr/n_fft):.0f} (at {150:.0f} Hz)\")\n",
    "print(f\"  2nd harmonic in bin #{300 // (sr/n_fft):.0f} (at 300 Hz)\")\n",
    "\n",
    "# --- Visualization ---\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "# Magnitude spectrogram (dB scale)\n",
    "img1 = librosa.display.specshow(\n",
    "    librosa.amplitude_to_db(magnitude, ref=np.max),\n",
    "    sr=sr, hop_length=hop_length, x_axis='time', y_axis='hz',\n",
    "    ax=axes[0], cmap='magma'\n",
    ")\n",
    "axes[0].set_title(\"Magnitude Spectrogram (dB)\", fontweight='bold')\n",
    "axes[0].set_ylim(0, 8000)  # Focus on speech range\n",
    "fig.colorbar(img1, ax=axes[0], format='%+2.0f dB')\n",
    "\n",
    "# Phase spectrogram\n",
    "img2 = axes[1].imshow(\n",
    "    phase[:200, :],  # Show only first 200 freq bins for clarity\n",
    "    aspect='auto', origin='lower', cmap='twilight',\n",
    "    extent=[0, len(y)/sr, 0, 200 * sr/n_fft]\n",
    ")\n",
    "axes[1].set_title(\"Phase (radians) — notice the 'random' pattern\", fontweight='bold')\n",
    "axes[1].set_xlabel(\"Time (s)\")\n",
    "axes[1].set_ylabel(\"Frequency (Hz)\")\n",
    "fig.colorbar(img2, ax=axes[1], label='Phase (rad)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ch01_stft.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nNote: Phase looks 'random' but is necessary for waveform reconstruction.\")\n",
    "print(\"VieNeu-TTS NeuCodec uses learned phase estimation — it does NOT discard phase.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d0e1f2",
   "metadata": {},
   "source": [
    "## 4. Mel Spectrogram\n",
    "\n",
    "The **mel spectrogram** applies a triangular mel filterbank to the power spectrogram, compressing the frequency axis from linear Hz to the perceptual mel scale:\n",
    "\n",
    "$$m = 2595 \\times \\log_{10}\\!\\left(1 + \\frac{f}{700}\\right)$$\n",
    "\n",
    "With 80 mel bins, the spectrogram focuses most resolution on the perceptually important 0–4 kHz range (where vowel formants and tone F0 live), and fewer bins on the 4–12 kHz range.\n",
    "\n",
    "**VieNeu-TTS uses the mel spectrogram for:**\n",
    "- Training loss computation (predicted mel vs target mel)\n",
    "- Visualization and debugging\n",
    "- The mel filterbank matrix is a fixed, non-learned transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e1f2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mels = 80  # VieNeu-TTS default: 80 mel bins\n",
    "fmin   = 0   # Minimum frequency (Hz)\n",
    "fmax   = None  # Maximum frequency (None = sr/2 = Nyquist)\n",
    "\n",
    "# Compute mel spectrogram\n",
    "mel_spec = librosa.feature.melspectrogram(\n",
    "    y=y, sr=sr,\n",
    "    n_fft=n_fft,\n",
    "    hop_length=hop_length,\n",
    "    n_mels=n_mels,\n",
    "    fmin=fmin,\n",
    "    fmax=fmax\n",
    ")\n",
    "mel_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "\n",
    "print(f\"Mel spectrogram shape: {mel_spec.shape}  ({n_mels} mel bins × {mel_spec.shape[1]} time frames)\")\n",
    "print(f\"Value range (dB):      [{mel_db.min():.1f}, {mel_db.max():.1f}] dB\")\n",
    "print()\n",
    "\n",
    "# Show the mel filterbank itself\n",
    "mel_filter = librosa.filters.mel(sr=sr, n_fft=n_fft, n_mels=n_mels)\n",
    "print(f\"Mel filterbank matrix shape: {mel_filter.shape}  ({n_mels} filters × {n_fft//2+1} FFT bins)\")\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 8))\n",
    "\n",
    "# --- Plot mel filterbank ---\n",
    "ax0 = axes[0]\n",
    "freqs = librosa.fft_frequencies(sr=sr, n_fft=n_fft)\n",
    "for i in range(0, n_mels, 8):  # Show every 8th filter to avoid clutter\n",
    "    ax0.plot(freqs, mel_filter[i], alpha=0.7, linewidth=1)\n",
    "ax0.set_title(f\"Mel Filterbank — {n_mels} triangular filters (every 8th shown)\", fontweight='bold')\n",
    "ax0.set_xlabel(\"Frequency (Hz)\")\n",
    "ax0.set_ylabel(\"Filter Weight\")\n",
    "ax0.set_xlim(0, sr//2)\n",
    "ax0.axvline(700, color='red', linestyle='--', alpha=0.5, label='700 Hz (mel break point)')\n",
    "ax0.legend(fontsize=8)\n",
    "\n",
    "# --- Mel Spectrogram ---\n",
    "ax1 = axes[1]\n",
    "img = librosa.display.specshow(\n",
    "    mel_db, sr=sr, hop_length=hop_length,\n",
    "    x_axis='time', y_axis='mel',\n",
    "    ax=ax1, cmap='magma'\n",
    ")\n",
    "ax1.set_title(f\"Log Mel Spectrogram — {n_mels} mel bins @ {sr} Hz sample rate\", fontweight='bold')\n",
    "fig.colorbar(img, ax=ax1, format='%+2.0f dB', label='Power (dB)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ch01_mel.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nObservation: Most energy is concentrated in the 0-4 kHz band (vowels, F0, formants).\")\n",
    "print(\"The mel scale uses more bins here and fewer bins at 4-12 kHz — matching human perception.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f2a3b4",
   "metadata": {},
   "source": [
    "## 5. MFCCs — Mel-Frequency Cepstral Coefficients\n",
    "\n",
    "MFCCs apply a **DCT** to the log mel spectrogram to decorrelate the filterbank outputs:\n",
    "\n",
    "$$c[n] = \\sum_{k=0}^{K-1} \\log(S[k]) \\cos\\!\\left(\\frac{\\pi n(k+0.5)}{K}\\right)$$\n",
    "\n",
    "The first 13 coefficients capture the **spectral envelope**. Delta and delta-delta MFCCs capture **temporal dynamics** — critically important for Vietnamese tone analysis:\n",
    "\n",
    "| Feature | What it captures | Vietnamese relevance |\n",
    "|---------|-----------------|---------------------|\n",
    "| MFCC (static) | Vowel quality, timbre | Same for all tones on same vowel |\n",
    "| Delta MFCC | Rate of spectral change | Encodes tone contour direction |\n",
    "| Delta-delta MFCC | Acceleration of change | Encodes contour shape (dip, break) |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a3b4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mfcc = 13  # Standard: keep first 13 coefficients\n",
    "\n",
    "# Compute MFCCs\n",
    "mfccs = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=n_mfcc,\n",
    "                               n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
    "\n",
    "# Compute delta and delta-delta\n",
    "mfcc_delta  = librosa.feature.delta(mfccs, order=1)  # Velocity\n",
    "mfcc_delta2 = librosa.feature.delta(mfccs, order=2)  # Acceleration\n",
    "\n",
    "# Stack into full 39-dim feature vector\n",
    "mfcc_full = np.vstack([mfccs, mfcc_delta, mfcc_delta2])\n",
    "\n",
    "print(f\"MFCC shape:        {mfccs.shape}    ({n_mfcc} coefficients × {mfccs.shape[1]} frames)\")\n",
    "print(f\"Delta MFCC shape:  {mfcc_delta.shape}\")\n",
    "print(f\"Delta² MFCC shape: {mfcc_delta2.shape}\")\n",
    "print(f\"Full feature (stacked): {mfcc_full.shape}  ({3*n_mfcc} dims × {mfccs.shape[1]} frames)\")\n",
    "\n",
    "# Visualize all three layers\n",
    "fig, axes = plt.subplots(3, 1, figsize=(14, 10))\n",
    "\n",
    "titles = [\n",
    "    f\"Static MFCCs (c₀–c₁₂) — Spectral Envelope / Vowel Quality\",\n",
    "    f\"Delta MFCCs (Δc) — Rate of Spectral Change (encodes tone direction)\",\n",
    "    f\"Delta-Delta MFCCs (Δ²c) — Acceleration (encodes tone shape: dip, break)\",\n",
    "]\n",
    "features = [mfccs, mfcc_delta, mfcc_delta2]\n",
    "cmaps    = ['coolwarm', 'PiYG', 'RdYlBu']\n",
    "\n",
    "for ax, feat, title, cmap in zip(axes, features, titles, cmaps):\n",
    "    img = librosa.display.specshow(feat, sr=sr, hop_length=hop_length,\n",
    "                                    x_axis='time', ax=ax, cmap=cmap)\n",
    "    ax.set_title(title, fontweight='bold')\n",
    "    ax.set_ylabel(\"MFCC Index\")\n",
    "    fig.colorbar(img, ax=ax)\n",
    "\n",
    "axes[-1].set_xlabel(\"Time (s)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig('ch01_mfcc.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nVietnamese tone fingerprints in MFCC features:\")\n",
    "print(\"  Ngang  (flat):    Δc[1] ≈ 0   (no change in spectral tilt)\")\n",
    "print(\"  Huyền  (falling): Δc[1] < 0   (spectrum tilts toward lower freqs as pitch falls)\")\n",
    "print(\"  Sắc    (rising):  Δc[1] > 0   (spectrum brightens as pitch rises)\")\n",
    "print(\"  Hỏi   (dipping): Δ²c[1] sign changes  (first falls then rises = inflection)\")\n",
    "print(\"  Nặng  (abrupt):  Large Δ²c negative spike at endpoint (fast deceleration)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b4c5d6",
   "metadata": {},
   "source": [
    "## 6. Nyquist Demo — Aliasing\n",
    "\n",
    "The **Nyquist-Shannon theorem** states that to faithfully represent a signal with bandwidth $B$ Hz,  \n",
    "you must sample at $f_s \\geq 2B$ Hz.\n",
    "\n",
    "If $f_s < 2B$, high-frequency components **alias** — they appear as spurious lower-frequency components:\n",
    "\n",
    "$$f_{\\text{alias}} = |f - k f_s|, \\quad \\text{for integer } k \\text{ s.t. } f_{\\text{alias}} \\in [0, f_s/2]$$\n",
    "\n",
    "Here we demonstrate aliasing by generating a 440 Hz tone (the musical note A4, used as a reference pitch in Vietnamese music), then undersampling it to cause aliasing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c5d6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate reference tone: 440 Hz (A4 = concert pitch, used in Vietnamese traditional music)\n",
    "sr_high = 24000   # High quality sample rate (VieNeu-TTS standard)\n",
    "sr_low  = 800     # Intentionally low — Nyquist = 400 Hz < 440 Hz → aliasing!\n",
    "duration = 1.0    # 1 second\n",
    "\n",
    "t_high = np.linspace(0, duration, int(sr_high * duration), endpoint=False)\n",
    "t_low  = np.linspace(0, duration, int(sr_low  * duration), endpoint=False)\n",
    "\n",
    "freq_original = 440.0  # Hz — A4\n",
    "\n",
    "# Original high-quality signal\n",
    "signal_high = np.sin(2 * np.pi * freq_original * t_high)\n",
    "\n",
    "# Undersampled signal (sampled at sr_low=800 Hz with Nyquist=400 Hz)\n",
    "signal_low = np.sin(2 * np.pi * freq_original * t_low)\n",
    "\n",
    "# Calculate alias frequency\n",
    "# 440 Hz sampled at 800 Hz:\n",
    "# 440 mod 800 = 440; but 440 > 400 (Nyquist), so alias = |440 - 800| = 360 Hz\n",
    "f_alias = abs(freq_original - sr_low)\n",
    "print(f\"Original frequency:   {freq_original} Hz\")\n",
    "print(f\"Undersample rate:     {sr_low} Hz\")\n",
    "print(f\"Nyquist limit:        {sr_low//2} Hz\")\n",
    "print(f\"Alias frequency:      |{freq_original:.0f} - {sr_low}| = {f_alias:.0f} Hz\")\n",
    "print(f\"→ 440 Hz appears as {f_alias:.0f} Hz after undersampling!\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 8))\n",
    "zoom_samples = 200  # Show first 200 samples\n",
    "\n",
    "# Time domain comparison\n",
    "axes[0,0].plot(t_high[:zoom_samples], signal_high[:zoom_samples], 'b-', linewidth=1.5, label=f'Original {freq_original:.0f} Hz')\n",
    "axes[0,0].set_title(f\"Original: {freq_original:.0f} Hz @ {sr_high} Hz sample rate\", fontweight='bold')\n",
    "axes[0,0].set_xlabel(\"Time (s)\")\n",
    "axes[0,0].set_ylabel(\"Amplitude\")\n",
    "axes[0,0].legend()\n",
    "\n",
    "axes[0,1].plot(t_low[:min(zoom_samples, len(t_low))],\n",
    "               signal_low[:min(zoom_samples, len(t_low))],\n",
    "               'r-o', linewidth=1.5, markersize=3, label=f'Aliased @ {sr_low} Hz')\n",
    "axes[0,1].set_title(f\"Aliased: {freq_original:.0f} Hz @ {sr_low} Hz sample rate → appears as {f_alias:.0f} Hz\",\n",
    "                    fontweight='bold', color='red')\n",
    "axes[0,1].set_xlabel(\"Time (s)\")\n",
    "axes[0,1].set_ylabel(\"Amplitude\")\n",
    "axes[0,1].legend()\n",
    "\n",
    "# Frequency domain comparison\n",
    "def plot_fft(ax, signal, sr, title, color):\n",
    "    N = len(signal)\n",
    "    freqs = np.fft.rfftfreq(N, 1/sr)\n",
    "    fft_mag = np.abs(np.fft.rfft(signal)) / N\n",
    "    ax.plot(freqs, fft_mag, color=color, linewidth=1.5)\n",
    "    ax.set_title(title, fontweight='bold')\n",
    "    ax.set_xlabel(\"Frequency (Hz)\")\n",
    "    ax.set_ylabel(\"|FFT|\")\n",
    "    ax.set_xlim(0, max(sr//2, 500))\n",
    "    ax.axvline(sr//2, color='gray', linestyle='--', alpha=0.5, label=f'Nyquist = {sr//2} Hz')\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "plot_fft(axes[1,0], signal_high, sr_high,\n",
    "         f\"FFT of original signal: spike at {freq_original:.0f} Hz\", 'blue')\n",
    "\n",
    "plot_fft(axes[1,1], signal_low, sr_low,\n",
    "         f\"FFT of aliased signal: spike at {f_alias:.0f} Hz (NOT {freq_original:.0f} Hz!)\", 'red')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('ch01_aliasing.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nConclusion: Sampling below Nyquist rate creates phantom frequencies.\")\n",
    "print(\"VieNeu-TTS uses 24 kHz to prevent aliasing for Vietnamese speech up to 12 kHz.\")\n",
    "print()\n",
    "print(\"Listen to both:\")\n",
    "display(Audio(signal_high, rate=sr_high))\n",
    "display(Audio(signal_low,  rate=sr_low))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d6e7f8",
   "metadata": {},
   "source": [
    "## 7. Effect of Hop Length & Window Size (Time-Frequency Trade-off)\n",
    "\n",
    "The **Heisenberg-Gabor uncertainty principle** for signals states:\n",
    "\n",
    "$$\\Delta t \\cdot \\Delta f \\geq \\frac{1}{4\\pi}$$\n",
    "\n",
    "You cannot simultaneously have:\n",
    "- **High time resolution** (fine temporal detail) — requires *small* window\n",
    "- **High frequency resolution** (fine spectral detail) — requires *large* window\n",
    "\n",
    "This grid shows 4 parameter combinations. Look at how the F0 harmonics and temporal boundaries change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e7f8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Four parameter combinations demonstrating the time-frequency trade-off\n",
    "configs = [\n",
    "    {\"n_fft\": 128,  \"hop\": 32,  \"label\": \"n_fft=128, hop=32\\n(High time res, Low freq res)\"},\n",
    "    {\"n_fft\": 512,  \"hop\": 128, \"label\": \"n_fft=512, hop=128\\n(Balanced — moderate)\"},\n",
    "    {\"n_fft\": 1024, \"hop\": 256, \"label\": \"n_fft=1024, hop=256\\n(VieNeu-TTS default)\"},\n",
    "    {\"n_fft\": 2048, \"hop\": 512, \"label\": \"n_fft=2048, hop=512\\n(Low time res, High freq res)\"},\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "axes_flat = axes.flatten()\n",
    "\n",
    "for ax, cfg in zip(axes_flat, configs):\n",
    "    D_cfg = librosa.stft(y, n_fft=cfg['n_fft'], hop_length=cfg['hop'])\n",
    "    mag_db = librosa.amplitude_to_db(np.abs(D_cfg), ref=np.max)\n",
    "\n",
    "    librosa.display.specshow(\n",
    "        mag_db, sr=sr, hop_length=cfg['hop'],\n",
    "        x_axis='time', y_axis='hz',\n",
    "        ax=ax, cmap='magma'\n",
    "    )\n",
    "    delta_f = sr / cfg['n_fft']\n",
    "    delta_t = cfg['hop'] / sr * 1000\n",
    "\n",
    "    title = (f\"{cfg['label']}\\n\"\n",
    "             f\"Δf={delta_f:.1f} Hz/bin | Δt={delta_t:.1f} ms/frame | \"\n",
    "             f\"Shape: {D_cfg.shape}\")\n",
    "    ax.set_title(title, fontsize=9, fontweight='bold')\n",
    "    ax.set_ylim(0, 6000)  # Focus on speech range\n",
    "\n",
    "plt.suptitle(\"Time-Frequency Resolution Trade-off\\nLarger n_fft → sharper frequency peaks; Smaller hop → finer time detail\",\n",
    "             fontsize=12, fontweight='bold', y=1.01)\n",
    "plt.tight_layout()\n",
    "plt.savefig('ch01_tradeoff.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nAnalysis:\")\n",
    "print(\"  n_fft=128:  You can see individual 'puffs' of consonants but F0 harmonics are blurred\")\n",
    "print(\"  n_fft=2048: F0 harmonics are razor-sharp but consonant transitions smear across 85ms\")\n",
    "print(\"  n_fft=1024: VieNeu-TTS choice — both F0 harmonics AND consonant boundaries are visible\")\n",
    "print()\n",
    "print(\"For Vietnamese:\")\n",
    "print(\"  - F0 resolution needed: < 10 Hz (distinguish 150 Hz from 160 Hz = semitone apart)\")\n",
    "print(f\"    n_fft=1024 gives {sr/1024:.1f} Hz/bin ✓\")\n",
    "print(\"  - Temporal resolution needed: < 20 ms (resolve consonant closures, tone onsets)\")\n",
    "print(f\"    hop=256 gives {256/sr*1000:.1f} ms/frame ✓\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f8a9b0",
   "metadata": {},
   "source": [
    "## Summary — Which Representation, When?\n",
    "\n",
    "| Representation | Formula | Shape | Used When |\n",
    "|---|---|---|---|\n",
    "| **Waveform** | `y[n]` | `(T,)` | Neural vocoder input/output; lossless storage |\n",
    "| **STFT** | `X[m,k] = Σ x[n]w[n-mH]e^{-j2πkn/N}` | `(N/2+1, T')` | Waveform reconstruction; phase modeling |\n",
    "| **Power spectrogram** | `\\|X[m,k]\\|²` | `(N/2+1, T')` | Energy analysis; vocoder features |\n",
    "| **Mel spectrogram** | `S[m,t] = Σ H_m(k)·P[k,t]` | `(80, T')` | TTS loss; visualization; most ML models |\n",
    "| **Log mel spectrogram** | `log(S[m,t])` | `(80, T')` | **VieNeu-TTS primary training target** |\n",
    "| **MFCCs** | DCT of log mel | `(13, T')` | ASR; speaker ID; tone analysis |\n",
    "| **Codec tokens** | RVQ of encoder output | `(T'', 8)` int | **VieNeu-TTS LLM input/output** |\n",
    "\n",
    "The key insight for VieNeu-TTS:\n",
    "- During **inference**: the model predicts discrete **codec tokens** (integers), not mel spectrograms\n",
    "- The **NeuCodec decoder** converts tokens → waveform directly, no separate mel-to-waveform vocoder needed\n",
    "- The **log mel spectrogram** is used for analysis, loss computation during codec training, and debugging\n",
    "- **MFCCs** are useful for tone analysis and understanding what the model has learned, but are not part of the inference pipeline\n",
    "\n",
    "Next: **Chapter 02** covers text normalization and phonemization — how Vietnamese text is converted to the phoneme sequence that feeds the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
