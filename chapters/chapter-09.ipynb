{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ch09-cell-01",
   "metadata": {},
   "source": [
    "# Chapter 9 — Training, Monitoring & Evaluation"
   ]
  },
  {
   "id": "colab-setup-ch09",
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# ── Colab auto-setup (safe to run locally too) ───────────────────\nimport sys, os\n\nif \"google.colab\" in sys.modules:\n    if not os.path.exists(\"/content/vietnamese-tts-course\"):\n        !git clone https://github.com/thinhdanggroup/vietnamese-tts-course.git /content/vietnamese-tts-course\n    os.chdir(\"/content/vietnamese-tts-course/chapters\")\n    !pip install -q librosa soundfile matplotlib\n\n    if not os.path.exists(\"/content/VieNeu-TTS\"):\n        !git clone https://github.com/pnnbao97/VieNeu-TTS.git /content/VieNeu-TTS\n        !pip install -q -e /content/VieNeu-TTS\n    sys.path.insert(0, \"/content/VieNeu-TTS\")\n    print(\"Colab setup complete.\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ch09-cell-02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ch09-cell-03",
   "metadata": {},
   "source": [
    "## 1. The Training Loss — What Are We Optimizing?\n",
    "\n",
    "For TTS, we compute cross-entropy **only on speech token positions** (text positions are masked with `-100`):\n",
    "\n",
    "$$\\mathcal{L} = -\\frac{1}{|S|} \\sum_{t \\in S} \\log P(s_t \\mid s_{<t},\\ \\text{context})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ch09-cell-04",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = np.arange(0, 5001, 50)\n",
    "np.random.seed(42)\n",
    "\n",
    "healthy = 2.5 * np.exp(-steps / 2000) + 1.8 + np.random.randn(len(steps)) * 0.05\n",
    "overfit = 2.5 * np.exp(-steps / 1500) + 1.5 + np.random.randn(len(steps)) * 0.03\n",
    "unstable = 2.5 * np.exp(-steps / 2000) + 1.8 + np.random.randn(len(steps)) * 0.15\n",
    "unstable[40] += 0.8; unstable[80] += 0.5\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "for ax, loss, title, color in zip(axes,\n",
    "    [healthy, overfit, unstable],\n",
    "    [\"Healthy Training\", \"Overfitting\", \"Unstable (LR too high)\"],\n",
    "    [\"green\", \"orange\", \"red\"]):\n",
    "    ax.plot(steps, loss, color=color, alpha=0.8)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"Step\")\n",
    "    ax.set_ylabel(\"Loss\")\n",
    "    ax.set_ylim(1.4, 3.2)\n",
    "    ax.axhline(y=1.8, color='gray', linestyle='--', alpha=0.5, label='Target ~1.8')\n",
    "    ax.legend()\n",
    "plt.suptitle(\"Training Loss Patterns — VieNeu-TTS LoRA\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ch09-cell-05",
   "metadata": {},
   "source": [
    "## 2. CER — Character Error Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ch09-cell-06",
   "metadata": {},
   "outputs": [],
   "source": [
    "def edit_distance(ref, hyp):\n",
    "    m, n = len(ref), len(hyp)\n",
    "    dp = [[0]*(n+1) for _ in range(m+1)]\n",
    "    for i in range(m+1): dp[i][0] = i\n",
    "    for j in range(n+1): dp[0][j] = j\n",
    "    for i in range(1, m+1):\n",
    "        for j in range(1, n+1):\n",
    "            dp[i][j] = dp[i-1][j-1] if ref[i-1]==hyp[j-1] else 1+min(dp[i-1][j],dp[i][j-1],dp[i-1][j-1])\n",
    "    return dp[m][n]\n",
    "\n",
    "def cer(reference, hypothesis):\n",
    "    ref = list(reference.replace(\" \", \"\"))\n",
    "    hyp = list(hypothesis.replace(\" \", \"\"))\n",
    "    return edit_distance(ref, hyp) / len(ref) * 100\n",
    "\n",
    "examples = [\n",
    "    (\"Xin ch\\u00e0o Vi\\u1ec7t Nam.\", \"Xin ch\\u00e0o Vi\\u1ec7t Nam.\"),\n",
    "    (\"H\\u00f4m nay tr\\u1eddi \\u0111\\u1eb9p.\", \"H\\u00f4m nay tr\\u1eddi \\u0111\\u1eb9p\"),\n",
    "    (\"T\\u00f4i l\\u00e0 VieNeu TTS.\", \"T\\u00f4i l\\u00e0 VieNeu TDS.\"),\n",
    "    (\"Machine learning th\\u00fa v\\u1ecb.\", \"Machine learning th\\u00fa v\\u1ecb.\"),\n",
    "    (\"N\\u0103m nay th\\u1eddi ti\\u1ebft l\\u1ea1nh.\", \"N\\u0103m nay th\\u1eddi ti\\u1ebft lanh.\"),\n",
    "]\n",
    "print(f\"{'Reference':<35} {'Hypothesis':<35} CER\")\n",
    "print(\"-\"*80)\n",
    "for ref, hyp in examples:\n",
    "    score = cer(ref, hyp)\n",
    "    print(f\"{ref:<35} {hyp:<35} {score:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ch09-cell-07",
   "metadata": {},
   "source": [
    "## 3. MCD — Mel Cepstral Distortion\n",
    "\n",
    "$$\\text{MCD} = \\frac{10\\sqrt{2}}{\\ln 10} \\cdot \\frac{1}{T} \\sum_{t=1}^{T} \\sqrt{\\sum_{d=1}^{D} (mc_d^{(t)} - \\hat{mc}_d^{(t)})^2}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ch09-cell-08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "from vieneu import Vieneu\n",
    "\n",
    "tts = Vieneu()\n",
    "test_text = \"H\\u1ec7 th\\u1ed1ng t\\u1ed5ng h\\u1ee3p ti\\u1ebfng Vi\\u1ec7t ho\\u1ea1t \\u0111\\u1ed9ng t\\u1ed1t.\"\n",
    "mfcc_data = {}\n",
    "\n",
    "for voice_id in [\"Binh\", \"Tuyen\", \"Ly\"]:\n",
    "    voice = tts.get_preset_voice(voice_id)\n",
    "    audio = tts.infer(test_text, voice=voice)\n",
    "    mfcc = librosa.feature.mfcc(y=audio, sr=24000, n_mfcc=13)\n",
    "    mfcc_data[voice_id] = mfcc\n",
    "    print(f\"Voice {voice_id}: {len(audio)/24000:.2f}s, MFCC shape: {mfcc.shape}\")\n",
    "\n",
    "tts.close()\n",
    "\n",
    "# MCD between voices\n",
    "voices = list(mfcc_data.keys())\n",
    "for i in range(len(voices)):\n",
    "    for j in range(i+1, len(voices)):\n",
    "        v1, v2 = voices[i], voices[j]\n",
    "        m1, m2 = mfcc_data[v1], mfcc_data[v2]\n",
    "        min_t = min(m1.shape[1], m2.shape[1])\n",
    "        diff = m1[1:, :min_t] - m2[1:, :min_t]\n",
    "        mcd = (10 * np.sqrt(2) / np.log(10)) * np.mean(np.sqrt(np.sum(diff**2, axis=0)))\n",
    "        print(f\"MCD({v1} vs {v2}): {mcd:.2f} dB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ch09-cell-09",
   "metadata": {},
   "source": [
    "## 4. Checkpoint Selection Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ch09-cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoints = [500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000]\n",
    "train_loss   = [2.40, 2.20, 2.10, 2.00, 1.95, 1.92, 1.90, 1.89, 1.88, 1.88]\n",
    "utmos_train  = [3.60, 3.80, 3.90, 4.00, 4.05, 4.10, 4.15, 4.18, 4.20, 4.22]\n",
    "utmos_test   = [3.50, 3.70, 3.90, 4.00, 4.05, 4.08, 4.07, 4.03, 3.98, 3.95]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 8))\n",
    "ax1.plot(checkpoints, train_loss, 'b-o', label=\"Train loss\")\n",
    "ax1.set_ylabel(\"Cross-entropy loss\"); ax1.legend(); ax1.set_title(\"Training Loss\")\n",
    "\n",
    "ax2.plot(checkpoints, utmos_train, 'g-o', label=\"UTMOS (train sentences)\")\n",
    "ax2.plot(checkpoints, utmos_test,  'r-o', label=\"UTMOS (test sentences)\")\n",
    "best_idx = np.argmax(utmos_test)\n",
    "best_step = checkpoints[best_idx]\n",
    "ax2.axvline(x=best_step, color='orange', linestyle='--', label=f\"Best: step {best_step}\")\n",
    "ax2.set_xlabel(\"Training step\"); ax2.set_ylabel(\"UTMOS\"); ax2.legend()\n",
    "ax2.set_title(\"Select checkpoint where TEST UTMOS peaks (not train)\")\n",
    "plt.tight_layout(); plt.show()\n",
    "print(f\"Best checkpoint: step {best_step} (UTMOS test = {utmos_test[best_idx]:.2f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ch09-cell-11",
   "metadata": {},
   "source": [
    "## 5. Vietnamese Tone Test Suite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ch09-cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "from vieneu import Vieneu\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "tts = Vieneu()\n",
    "voice = tts.get_preset_voice(\"Binh\")\n",
    "\n",
    "tone_tests = [\n",
    "    (\"ma\",  \"ngang \\u2014 flat level\"),\n",
    "    (\"m\\u00e0\",  \"huyen \\u2014 falling\"),\n",
    "    (\"m\\u00e1\",  \"sac \\u2014 rising\"),\n",
    "    (\"m\\u1ea3\",  \"hoi \\u2014 dipping-rising\"),\n",
    "    (\"m\\u00e3\",  \"nga \\u2014 creaky rising\"),\n",
    "    (\"m\\u1ea1\",  \"nang \\u2014 heavy falling\"),\n",
    "]\n",
    "\n",
    "for syllable, description in tone_tests:\n",
    "    text = f\"\\u00c2m ti\\u1ebft {syllable} mang thanh {description.split('\\u2014')[0].strip()}.\"\n",
    "    audio = tts.infer(text, voice=voice)\n",
    "    print(f\"{syllable} ({description}): {len(audio)/24000:.2f}s\")\n",
    "    display(Audio(audio, rate=24000))\n",
    "\n",
    "tts.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ch09-cell-13",
   "metadata": {},
   "source": [
    "## 6. Evaluation Summary\n",
    "\n",
    "| Metric | Type | How to Compute | Target |\n",
    "|--------|------|----------------|--------|\n",
    "| CER | Objective | ASR → edit distance | < 5% |\n",
    "| WER | Objective | ASR → word edit distance | < 10% |\n",
    "| MCD | Objective | MFCC distance ref vs gen | < 8 dB |\n",
    "| UTMOS | Semi-objective | Neural MOS predictor | > 3.8 |\n",
    "| MOS | Subjective | Human rating 1–5 | > 4.0 |\n",
    "| AB Test | Subjective | Which sounds better? | > 60% prefer |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}